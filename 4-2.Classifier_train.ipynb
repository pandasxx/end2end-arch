{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end model:Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 read feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du ### 0\n",
      "du (500, 128, 128, 512)\n",
      "du (500,)\n",
      "du (500, 128, 128, 512)\n",
      "du (500,)\n",
      "du *** 1\n",
      "du (500, 128, 128, 512)\n",
      "du (500,)\n",
      "du (491, 128, 128, 512)\n",
      "du (491,)\n",
      "du *** 2\n",
      "du (991, 128, 128, 512)\n",
      "du (991,)\n",
      "du (500, 128, 128, 512)\n",
      "du (500,)\n",
      "du *** 3\n",
      "du (1491, 128, 128, 512)\n",
      "du (1491,)\n",
      "du (500, 128, 128, 512)\n",
      "du (500,)\n",
      "du (1991, 128, 128, 512)\n",
      "du (1991,)\n"
     ]
    }
   ],
   "source": [
    "h5_files = ['/home/tsimage/high_speed_data/end2end_feature/feature_label_500.h5',\n",
    "            '/home/tsimage/high_speed_data/end2end_feature/feature_label_1000.h5',\n",
    "            '/home/tsimage/high_speed_data/end2end_feature/feature_label_1500.h5',\n",
    "            '/home/tsimage/high_speed_data/end2end_feature/feature_label_2000.h5']\n",
    "\n",
    "for i, h5_file in enumerate(h5_files):\n",
    "    h5f = h5py.File(h5_file,'r')\n",
    "    features_h5 = h5f['features'][:]\n",
    "    labels_h5 = h5f['labels'][:]\n",
    "    h5f.close()\n",
    "    if (i == 0):\n",
    "        print(\"du ###\",i)\n",
    "        features_h5_all = features_h5\n",
    "        labels_h5_all = labels_h5\n",
    "        print(\"du\", features_h5_all.shape)\n",
    "        print(\"du\", labels_h5_all.shape)\n",
    "        print(\"du\", features_h5.shape)\n",
    "        print(\"du\", labels_h5.shape)\n",
    "        features_h5 = None\n",
    "        labels_h5 = None\n",
    "    else:\n",
    "        print(\"du ***\",i)\n",
    "        print(\"du\", features_h5_all.shape)\n",
    "        print(\"du\", labels_h5_all.shape)\n",
    "        print(\"du\", features_h5.shape)\n",
    "        print(\"du\", labels_h5.shape)\n",
    "        features_h5_all = np.append(features_h5_all, features_h5, axis = 0)\n",
    "        labels_h5_all = np.append(labels_h5_all, labels_h5,  axis = 0)\n",
    "        features_h5 = None\n",
    "        labels_h5 = None\n",
    "        \n",
    "print(\"du\", features_h5_all.shape)\n",
    "print(\"du\", labels_h5_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du (1991, 128, 128, 512)\n",
      "du (1991, 1)\n",
      "du (1991, 128, 128, 512)\n",
      "du (1991, 2)\n",
      "du (1991, 128, 128, 512)\n",
      "du (1991, 2)\n"
     ]
    }
   ],
   "source": [
    "features = features_h5_all\n",
    "labels = labels_h5_all.reshape([len(labels_h5_all),1])\n",
    "features_h5_all = None\n",
    "labels_h5_all = None\n",
    "\n",
    "print(\"du\", features.shape)\n",
    "print(\"du\", labels.shape)\n",
    "\n",
    "labels = to_categorical(labels,2)\n",
    "print(\"du\", features.shape)\n",
    "print(\"du\", labels.shape)\n",
    "\n",
    "index = [i for i in range(len(features))]  \n",
    "random.shuffle(index)\n",
    "features = features[index]\n",
    "labels = labels[index]\n",
    "\n",
    "print(\"du\", features.shape)\n",
    "print(\"du\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 128, 128, 1024)    4719616   \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 128, 128, 1024)    1049600   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 64, 64, 2048)      18876416  \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 64, 64, 2048)      4196352   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 2048)      0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 32, 32, 4096)      75501568  \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 32, 32, 2048)      8390656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 2048)      0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 16, 16, 4096)      75501568  \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 16, 16, 2048)      8390656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 8, 8, 4096)        75501568  \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 8, 8, 2048)        8390656   \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "drop_fc1 (Dropout)           (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 280,522,754\n",
      "Trainable params: 280,522,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 512 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 512 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 128, 512 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 128, 512 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 512 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 2)            280522754   lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Concatenate)           (None, 2)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 280,522,754\n",
      "Trainable params: 280,522,754\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input((128, 128, 512))\n",
    "    \n",
    "    conv1_1 = Conv2D(filters = 1024, kernel_size = (3, 3), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv1_1')(input_tensor)\n",
    "    conv1_2 = Conv2D(filters = 1024, kernel_size = (1, 1), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv1_2')(conv1_1)\n",
    "    mp1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(conv1_2)\n",
    "    \n",
    "    conv2_1 = Conv2D(filters = 2048, kernel_size = (3, 3), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv2_1')(mp1)\n",
    "    conv2_2 = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv2_2')(conv2_1)\n",
    "    mp2 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(conv2_2)\n",
    "    \n",
    "    conv3_1 = Conv2D(filters = 4096, kernel_size = (3, 3), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv3_1')(mp2)\n",
    "    conv3_2 = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv3_2')(conv3_1)\n",
    "    mp3 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(conv3_2)\n",
    "    \n",
    "    conv4_1 = Conv2D(filters = 4096, kernel_size = (3, 3), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv4_1')(mp3)\n",
    "    conv4_2 = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv4_2')(conv4_1)\n",
    "    mp4 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(conv4_2)\n",
    "    \n",
    "    conv5_1 = Conv2D(filters = 4096, kernel_size = (3, 3), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv5_1')(mp4)\n",
    "    conv5_2 = Conv2D(filters = 2048, kernel_size = (1, 1), strides = (1, 1),\n",
    "                   activation='relu', padding='same', name='conv5_2')(conv5_1)\n",
    "    \n",
    "#    flatten = Flatten(name='flatten')(conv8)\n",
    "#    fc1 = Dense(1024, activation='relu', name='fc1')(flatten)\n",
    "#    gap = GlobalAveragePooling2D()(conv8)\n",
    "    gmp = GlobalMaxPooling2D()(conv5_2)\n",
    "    drop = Dropout(0.5, name='drop_fc1')(gmp)\n",
    "    predictions = Dense(2, activation='softmax')(drop)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=predictions)\n",
    "    model.summary()\n",
    "# LearningRate = LearningRate * 1/(1 + decay * epoch)\n",
    "    sgd = optimizers.SGD(lr=0.001, decay=0.001 * 100, momentum=0.9, nesterov=True)\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "#parallel_model.compile(optimizer='Adadelta', \n",
    "#                       loss='categorical_crossentropy', \n",
    "#                       metrics=['accuracy'])\n",
    "parallel_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "parallel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du (1991, 128, 128, 512)\n",
      "du (1991, 2)\n",
      "Train on 1592 samples, validate on 399 samples\n",
      "Epoch 1/100\n",
      "1592/1592 [==============================] - 255s 160ms/step - loss: 0.5386 - acc: 0.7657 - val_loss: 0.5531 - val_acc: 0.7343\n",
      "Epoch 2/100\n",
      "1584/1592 [============================>.] - ETA: 1s - loss: 0.5195 - acc: 0.7664"
     ]
    }
   ],
   "source": [
    "print(\"du\", features.shape)\n",
    "print(\"du\", labels.shape)\n",
    "parallel_model.fit(x=features, y=labels, \n",
    "                   batch_size=16, epochs=100, verbose=1, validation_split=0.2)\n",
    "model.save_weights(\"diagnosis.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### use sgd\n",
    "(1991, 128, 128, 512)\n",
    "du (1991, 2)\n",
    "Train on 1592 samples, validate on 399 samples\n",
    "Epoch 1/100\n",
    "1592/1592 [==============================] - 261s 164ms/step - loss: 0.5493 - acc: 0.7563 - val_loss: 0.5050 - val_acc: 0.7744\n",
    "Epoch 2/100\n",
    "1592/1592 [==============================] - 245s 154ms/step - loss: 0.5126 - acc: 0.7563 - val_loss: 0.4751 - val_acc: 0.7744\n",
    "Epoch 3/100\n",
    "1592/1592 [==============================] - 245s 154ms/step - loss: 0.4957 - acc: 0.7563 - val_loss: 0.4657 - val_acc: 0.7744\n",
    "Epoch 4/100\n",
    "1592/1592 [==============================] - 246s 154ms/step - loss: 0.4690 - acc: 0.7563 - val_loss: 0.5274 - val_acc: 0.8446\n",
    "Epoch 5/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.4889 - acc: 0.7619 - val_loss: 0.4390 - val_acc: 0.7744\n",
    "Epoch 6/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.4466 - acc: 0.8065 - val_loss: 0.4691 - val_acc: 0.7870\n",
    "Epoch 7/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.4403 - acc: 0.8034 - val_loss: 0.4116 - val_acc: 0.8697\n",
    "Epoch 8/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.4092 - acc: 0.8367 - val_loss: 0.4116 - val_acc: 0.8546\n",
    "Epoch 9/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.4005 - acc: 0.8398 - val_loss: 0.3637 - val_acc: 0.8847\n",
    "Epoch 10/100\n",
    "1592/1592 [==============================] - 249s 156ms/step - loss: 0.3774 - acc: 0.8480 - val_loss: 0.3688 - val_acc: 0.8546\n",
    "Epoch 11/100\n",
    "1592/1592 [==============================] - 249s 156ms/step - loss: 0.3726 - acc: 0.8411 - val_loss: 0.5530 - val_acc: 0.7744\n",
    "Epoch 12/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.3694 - acc: 0.8448 - val_loss: 0.4641 - val_acc: 0.7769\n",
    "Epoch 13/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.3649 - acc: 0.8455 - val_loss: 0.3210 - val_acc: 0.8772\n",
    "Epoch 14/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.3699 - acc: 0.8354 - val_loss: 0.3399 - val_acc: 0.8822\n",
    "Epoch 15/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.3509 - acc: 0.8555 - val_loss: 0.3752 - val_acc: 0.8546\n",
    "Epoch 16/100\n",
    "1592/1592 [==============================] - 246s 154ms/step - loss: 0.3470 - acc: 0.8536 - val_loss: 0.3162 - val_acc: 0.8922\n",
    "Epoch 17/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.3344 - acc: 0.8574 - val_loss: 0.3222 - val_acc: 0.8797\n",
    "Epoch 18/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.3352 - acc: 0.8562 - val_loss: 0.3446 - val_acc: 0.8747\n",
    "Epoch 19/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.3191 - acc: 0.8624 - val_loss: 0.3349 - val_acc: 0.8772\n",
    "Epoch 20/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.3233 - acc: 0.8543 - val_loss: 0.3266 - val_acc: 0.8772\n",
    "Epoch 21/100\n",
    "1592/1592 [==============================] - 249s 156ms/step - loss: 0.3293 - acc: 0.8555 - val_loss: 0.3073 - val_acc: 0.8747\n",
    "Epoch 22/100\n",
    "1592/1592 [==============================] - 245s 154ms/step - loss: 0.3079 - acc: 0.8693 - val_loss: 0.2785 - val_acc: 0.8872\n",
    "Epoch 23/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2889 - acc: 0.8763 - val_loss: 0.3887 - val_acc: 0.8095\n",
    "Epoch 24/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2971 - acc: 0.8599 - val_loss: 0.3806 - val_acc: 0.8571\n",
    "Epoch 25/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2902 - acc: 0.8737 - val_loss: 0.2491 - val_acc: 0.8997\n",
    "Epoch 26/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.3252 - acc: 0.8668 - val_loss: 0.2662 - val_acc: 0.8947\n",
    "Epoch 27/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.2824 - acc: 0.8825 - val_loss: 0.3140 - val_acc: 0.8747\n",
    "Epoch 28/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2704 - acc: 0.8844 - val_loss: 0.2405 - val_acc: 0.9048\n",
    "Epoch 29/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.2895 - acc: 0.8706 - val_loss: 0.2520 - val_acc: 0.8922\n",
    "Epoch 30/100\n",
    "1592/1592 [==============================] - 249s 157ms/step - loss: 0.2849 - acc: 0.8744 - val_loss: 0.2430 - val_acc: 0.9098\n",
    "Epoch 31/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.2569 - acc: 0.8781 - val_loss: 0.3845 - val_acc: 0.8797\n",
    "Epoch 32/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2650 - acc: 0.8781 - val_loss: 0.2286 - val_acc: 0.9173\n",
    "Epoch 33/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.2624 - acc: 0.8750 - val_loss: 0.2381 - val_acc: 0.8947\n",
    "Epoch 34/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2458 - acc: 0.8957 - val_loss: 0.2347 - val_acc: 0.8972\n",
    "Epoch 35/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2643 - acc: 0.8894 - val_loss: 0.2488 - val_acc: 0.8922\n",
    "Epoch 36/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2426 - acc: 0.8869 - val_loss: 0.5529 - val_acc: 0.8521\n",
    "Epoch 37/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.2667 - acc: 0.8769 - val_loss: 0.2174 - val_acc: 0.9248\n",
    "Epoch 38/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.2950 - acc: 0.8693 - val_loss: 0.2781 - val_acc: 0.8922\n",
    "Epoch 39/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.2410 - acc: 0.8945 - val_loss: 0.2123 - val_acc: 0.9148\n",
    "Epoch 40/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.2352 - acc: 0.8957 - val_loss: 0.2122 - val_acc: 0.9223\n",
    "Epoch 41/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2265 - acc: 0.9058 - val_loss: 0.1939 - val_acc: 0.9223\n",
    "Epoch 42/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.2273 - acc: 0.9033 - val_loss: 0.2210 - val_acc: 0.9248\n",
    "Epoch 43/100\n",
    "1592/1592 [==============================] - 249s 156ms/step - loss: 0.2060 - acc: 0.9146 - val_loss: 0.1903 - val_acc: 0.9223\n",
    "Epoch 44/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2133 - acc: 0.8970 - val_loss: 0.2516 - val_acc: 0.9148\n",
    "Epoch 45/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2172 - acc: 0.9102 - val_loss: 0.3828 - val_acc: 0.8697\n",
    "Epoch 46/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.1885 - acc: 0.9240 - val_loss: 0.2486 - val_acc: 0.9023\n",
    "Epoch 47/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.2195 - acc: 0.9014 - val_loss: 0.2153 - val_acc: 0.9173\n",
    "Epoch 48/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2061 - acc: 0.9102 - val_loss: 0.1922 - val_acc: 0.9373\n",
    "Epoch 49/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2002 - acc: 0.9165 - val_loss: 0.1797 - val_acc: 0.9323\n",
    "Epoch 50/100\n",
    "1592/1592 [==============================] - 249s 156ms/step - loss: 0.1939 - acc: 0.9139 - val_loss: 0.2536 - val_acc: 0.9148\n",
    "Epoch 51/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.2025 - acc: 0.9234 - val_loss: 0.2074 - val_acc: 0.9223\n",
    "Epoch 52/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1888 - acc: 0.9190 - val_loss: 0.2761 - val_acc: 0.8897\n",
    "Epoch 53/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 0.1804 - acc: 0.9177 - val_loss: 0.3558 - val_acc: 0.8822\n",
    "Epoch 54/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1900 - acc: 0.9227 - val_loss: 0.4040 - val_acc: 0.7820\n",
    "Epoch 55/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1871 - acc: 0.9171 - val_loss: 0.2429 - val_acc: 0.9073\n",
    "Epoch 56/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1747 - acc: 0.9347 - val_loss: 0.2736 - val_acc: 0.9098\n",
    "Epoch 57/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1643 - acc: 0.9309 - val_loss: 0.1852 - val_acc: 0.9298\n",
    "Epoch 58/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1491 - acc: 0.9334 - val_loss: 0.3358 - val_acc: 0.8371\n",
    "Epoch 59/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 0.1692 - acc: 0.9296 - val_loss: 0.1711 - val_acc: 0.9449\n",
    "Epoch 60/100\n",
    "1592/1592 [==============================] - 249s 156ms/step - loss: 0.1665 - acc: 0.9340 - val_loss: 0.1893 - val_acc: 0.9323\n",
    "Epoch 61/100\n",
    "1592/1592 [==============================] - 248s 156ms/step - loss: 0.1526 - acc: 0.9422 - val_loss: 0.7670 - val_acc: 0.8271\n",
    "Epoch 62/100\n",
    "1360/1592 [========================>.....] - ETA: 31s - loss: 0.1703 - acc: 0.9309\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-5-e03e9a10aac4> in <module>()\n",
    "      2 print(\"du\", labels.shape)\n",
    "      3 parallel_model.fit(x=features, y=labels, \n",
    "----> 4                    batch_size=16, epochs=100, verbose=1, validation_split=0.2)\n",
    "      5 model.save_weights(\"diagnosis.h5\")\n",
    "\n",
    "~/anaconda3/envs/algo-work/lib/python3.5/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\n",
    "   1040                                         initial_epoch=initial_epoch,\n",
    "   1041                                         steps_per_epoch=steps_per_epoch,\n",
    "-> 1042                                         validation_steps=validation_steps)\n",
    "   1043 \n",
    "   1044     def evaluate(self, x=None, y=None,\n",
    "\n",
    "~/anaconda3/envs/algo-work/lib/python3.5/site-packages/keras/engine/training_arrays.py in fit_loop(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\n",
    "    197                     ins_batch[i] = ins_batch[i].toarray()\n",
    "    198 \n",
    "--> 199                 outs = f(ins_batch)\n",
    "    200                 if not isinstance(outs, list):\n",
    "    201                     outs = [outs]\n",
    "\n",
    "~/anaconda3/envs/algo-work/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in __call__(self, inputs)\n",
    "   2659                 return self._legacy_call(inputs)\n",
    "   2660 \n",
    "-> 2661             return self._call(inputs)\n",
    "   2662         else:\n",
    "   2663             if py_any(is_tensor(x) for x in inputs):\n",
    "\n",
    "~/anaconda3/envs/algo-work/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in _call(self, inputs)\n",
    "   2629                                 symbol_vals,\n",
    "   2630                                 session)\n",
    "-> 2631         fetched = self._callable_fn(*array_vals)\n",
    "   2632         return fetched[:len(self.outputs)]\n",
    "   2633 \n",
    "\n",
    "~/anaconda3/envs/algo-work/lib/python3.5/site-packages/tensorflow/python/client/session.py in __call__(self, *args)\n",
    "   1449         if self._session._created_with_new_api:\n",
    "   1450           return tf_session.TF_SessionRunCallable(\n",
    "-> 1451               self._session._session, self._handle, args, status, None)\n",
    "   1452         else:\n",
    "   1453           return tf_session.TF_DeprecatedSessionRunCallable(\n",
    "\n",
    "KeyboardInterrupt: \n",
    "\n",
    "\n",
    "​\n",
    "\n",
    "\n",
    "​\n",
    "\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### use Adadelta\n",
    " (1991, 128, 128, 512)\n",
    "du (1991, 2)\n",
    "Train on 1592 samples, validate on 399 samples\n",
    "Epoch 1/100\n",
    "1592/1592 [==============================] - 258s 162ms/step - loss: 3.8041 - acc: 0.7575 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 2/100\n",
    "1592/1592 [==============================] - 245s 154ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 3/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 4/100\n",
    "1592/1592 [==============================] - 247s 155ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 5/100\n",
    "1592/1592 [==============================] - 245s 154ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 6/100\n",
    "1592/1592 [==============================] - 245s 154ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 7/100\n",
    "1592/1592 [==============================] - 246s 155ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 8/100\n",
    "1592/1592 [==============================] - 246s 154ms/step - loss: 3.8270 - acc: 0.7626 - val_loss: 4.0396 - val_acc: 0.7494\n",
    "Epoch 9/100\n",
    " 992/1592 [=================>............] - ETA: 1:21 - loss: 3.7696 - acc: 0.7661\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
